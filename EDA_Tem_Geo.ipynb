{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Initial Data ---\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('train_cleaned_c-10-21.csv')\n",
    "details_df = pd.read_csv('auxiliary-data/sg-hdb-block-details.csv')\n",
    "\n",
    "original_count = len(train_df)\n",
    "print(f\"Original 'train.csv' data has {original_count} rows.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. Clean and Prepare Data for Merging ---\n",
    "# For safety, we operate on copies\n",
    "train_clean_df = train_df.copy()\n",
    "details_clean_df = details_df.copy()\n",
    "\n",
    "# Convert key fields ('town'/'TOWN', 'block'/'BLOCK') in both DataFrames\n",
    "# to lowercase strings and strip leading/trailing whitespace to create join keys\n",
    "train_clean_df['join_key_town'] = train_clean_df['TOWN'].str.lower().str.strip()\n",
    "train_clean_df['join_key_block'] = train_clean_df['BLOCK'].astype(str).str.lower().str.strip()\n",
    "\n",
    "details_clean_df['join_key_town'] = details_clean_df['TOWN'].str.lower().str.strip()\n",
    "details_clean_df['join_key_block'] = details_clean_df['BLOCK'].astype(str).str.lower().str.strip()\n",
    "print(\"Data cleaning complete.\")\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19293a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Merge Training Data with Block Details (to get coordinates) ---\n",
    "print(\"Starting data merge...\")\n",
    "# Perform a left merge, using train_clean_df as the left table\n",
    "# how='left' means every row from train_clean_df will be kept\n",
    "merged_df = pd.merge(\n",
    "    train_clean_df,\n",
    "    details_clean_df,\n",
    "    on=['join_key_town', 'join_key_block'],  # Match using the standardized keys we created\n",
    "    how='left'\n",
    ")\n",
    "merged_df.to_csv('merged_latitude.csv', index=False)\n",
    "print(f\"Total rows after merge: {len(merged_df)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4. Load Amenity Data ---\n",
    "print(\"Loading amenity datasets...\")\n",
    "merged_df = pd.read_csv('merged_latitude.csv')\n",
    "subfolder = 'auxiliary-data'\n",
    "hawkers_df = pd.read_csv(subfolder + '/' + 'sg-gov-hawkers.csv')\n",
    "mrt_df = pd.read_csv(subfolder + '/' + 'sg-mrt-stations.csv')\n",
    "primary_schools_df = pd.read_csv(subfolder + '/' + 'sg-primary-schools.csv')\n",
    "print(\"Amenity data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Define Distance Calculation Function ---\n",
    "def calculate_distance_features(main_df, amenities_df, radius_km=1.0, description=\"Processing\"):\n",
    "    \"\"\"\n",
    "    For each row in main_df, calculate distances to all points in amenities_df and extract features.\n",
    "    (Includes a tqdm progress bar)\n",
    "\n",
    "    Args:\n",
    "    - main_df: DataFrame containing properties and their coordinates ('LATITUDE', 'LONGITUDE').\n",
    "    - amenities_df: DataFrame containing amenities and their coordinates ('LATITUDE', 'LONGITUDE').\n",
    "    - radius_km: The radius (in km) used to count amenities within range.\n",
    "    - description: Description text for the progress bar.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of two Series: (min_distance, count_within_radius).\n",
    "    \"\"\"\n",
    "    \n",
    "    min_distances = []\n",
    "    count_within_radius = []\n",
    "\n",
    "    # Wrap the iterator with tqdm in the loop\n",
    "    # It's good practice to provide the 'total' parameter when using .iterrows()\n",
    "    iterator = tqdm(main_df.iterrows(), total=main_df.shape[0], desc=description)\n",
    "\n",
    "    for house_index, house in iterator:\n",
    "        # Note: The coordinate columns might have suffixes like _x or _y after merging\n",
    "        house_coords = (house['LATITUDE'], house['LONGITUDE']) \n",
    "        \n",
    "        if pd.isna(house_coords[0]) or pd.isna(house_coords[1]):\n",
    "            min_distances.append(np.nan)\n",
    "            count_within_radius.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        distances = [\n",
    "            geodesic(house_coords, (amenity['LATITUDE'], amenity['LONGITUDE'])).kilometers\n",
    "            for amenity_index, amenity in amenities_df.iterrows()\n",
    "        ]\n",
    "        \n",
    "        if not distances:\n",
    "            min_distances.append(np.nan)\n",
    "            count_within_radius.append(0)\n",
    "        else:\n",
    "            min_distances.append(min(distances))\n",
    "            count_within_radius.append(sum(1 for d in distances if d <= radius_km))\n",
    "            \n",
    "    return pd.Series(min_distances, index=main_df.index), pd.Series(count_within_radius, index=main_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Calculate and Add Amenity Features ---\n",
    "print(\"Calculating distance features for MRT stations...\")\n",
    "# Calculate nearest distance to MRT and count of MRT stations within 1km\n",
    "dist_mrt, num_mrt = calculate_distance_features(merged_df, mrt_df, radius_km=1.0, description=\"Calculating MRT\")\n",
    "merged_df['dist_to_nearest_mrt'] = dist_mrt\n",
    "merged_df['num_mrt_within_1km'] = num_mrt\n",
    "print(\"MRT station features calculation complete.\")\n",
    "\n",
    "print(\"Calculating distance features for Hawker Centres...\")\n",
    "# Calculate nearest distance to Hawker Centre and count within 1km\n",
    "dist_hawker, num_hawker = calculate_distance_features(merged_df, hawkers_df, radius_km=1.0, description=\"Calculating Hawkers\")\n",
    "merged_df['dist_to_nearest_hawker'] = dist_hawker\n",
    "merged_df['num_hawkers_within_1km'] = num_hawker\n",
    "print(\"Hawker Centre features calculation complete.\")\n",
    "\n",
    "print(\"Calculating distance features for Primary Schools...\")\n",
    "# Calculate nearest distance to Primary School and count within 2km (School districts can be larger)\n",
    "dist_primary, num_primary = calculate_distance_features(merged_df, primary_schools_df, radius_km=2.0, description=\"Calculating Schools\")\n",
    "merged_df['dist_to_nearest_primary_school'] = dist_primary\n",
    "merged_df['num_primary_schools_within_2km'] = num_primary\n",
    "print(\"Primary School features calculation complete.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "merged_df.to_csv('merged_with_amenities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3653423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Final Cleanup and Saving ---\n",
    "print(\"All features added. Cleaning up final DataFrame...\")\n",
    "df = pd.read_csv(\"merged_with_amenities.csv\")\n",
    "\n",
    "# Drop intermediate, redundant, or sensitive columns\n",
    "df = df.drop(columns=[\n",
    "    'month', 'TOWN_x', 'BLOCK_x', 'join_key_town', 'join_key_block',\n",
    "    'TOWN_y', 'BLOCK_y', 'ADDRESS', 'POSTAL_CODE', 'LATITUDE', 'LONGITUDE'\n",
    "])\n",
    "print(\"Final columns:\", df.columns)\n",
    "\n",
    "# Drop duplicates based on ID, keeping the first entry\n",
    "df = df.drop_duplicates(subset=['ID'], keep='first')\n",
    "print(f\"Total rows after dropping duplicates: {len(df)}\")\n",
    "\n",
    "# Save the final feature-engineered dataset\n",
    "df.to_csv(\"train_cleaned_fe_geo_final.csv\", index=False)\n",
    "print(\"Processing complete. Final file saved as 'train_cleaned_fe_geo_final.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
